{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24ab2ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "315e0592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SE Block\n",
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, in_channels, r=16):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.squeeze = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.excitation = nn.Sequential(\n",
    "            nn.Linear(in_channels, in_channels//r),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_channels//r, in_channels),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.squeeze(x)\n",
    "        x = x.view(x.size(0), -1) \n",
    "        x = self.excitation(x)\n",
    "        return x.view(x.size(0), x.size(1), 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "864ccbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depthwise Separable Convolution\n",
    "class Depthwise(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.depthwise = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, in_channels, 3, stride=stride, padding=1, groups=in_channels, bias=False),\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU6(),\n",
    "        )\n",
    "\n",
    "        self.pointwise = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 1, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU6(),\n",
    "        )\n",
    "\n",
    "        self.seblock = SEBlock(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        return self.seblock(x) * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "collectible-bloom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model - MobileNet V1\n",
    "class MobileNet(nn.Module):\n",
    "    def __init__(self, width_multiplier, num_classes=10, init_weights=True):\n",
    "        super().__init__()\n",
    "        self.init_weights=init_weights\n",
    "        alpha = width_multiplier\n",
    "    \n",
    "        # Basic Conv\n",
    "        self.conv_layer_1 = nn.Sequential(\n",
    "            nn.Conv2d(3, int(32*alpha), kernel_size=3, stride=2, padding=1),\n",
    "            nn.BatchNorm2d(int(32*alpha)),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.conv_layer_2 = Depthwise(int(32*alpha), int(64*alpha), stride=1)\n",
    "        \n",
    "        # down sample\n",
    "        self.conv_layer_3 = nn.Sequential(\n",
    "            Depthwise(int(64*alpha), int(128*alpha), stride=2),\n",
    "            Depthwise(int(128*alpha), int(128*alpha), stride=1)\n",
    "        )\n",
    "        \n",
    "        # down sample\n",
    "        self.conv_layer_4 = nn.Sequential(\n",
    "            Depthwise(int(128*alpha), int(256*alpha), stride=2),\n",
    "            Depthwise(int(256*alpha), int(256*alpha), stride=1)\n",
    "        )\n",
    "        \n",
    "        # down sample\n",
    "        self.conv_layer_5 = nn.Sequential(\n",
    "            Depthwise(int(256*alpha), int(512*alpha), stride=2),\n",
    "            Depthwise(int(512*alpha), int(512*alpha), stride=1),\n",
    "            Depthwise(int(512*alpha), int(512*alpha), stride=1),\n",
    "            Depthwise(int(512*alpha), int(512*alpha), stride=1),\n",
    "            Depthwise(int(512*alpha), int(512*alpha), stride=1),\n",
    "            Depthwise(int(512*alpha), int(512*alpha), stride=1),\n",
    "        )\n",
    "        \n",
    "        # down sample\n",
    "        self.conv_layer_6 = nn.Sequential(\n",
    "            Depthwise(int(512*alpha), int(1024*alpha), stride=2)\n",
    "        )\n",
    "        \n",
    "        # down sample\n",
    "        self.conv_layer_7 = nn.Sequential(\n",
    "            Depthwise(int(1024*alpha), int(1024*alpha), stride=2)\n",
    "        )\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc_layer = nn.Linear(int(1024*alpha), num_classes)\n",
    "\n",
    "        # weights initialization\n",
    "        if self.init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layer_1(x)\n",
    "        x = self.conv_layer_2(x)\n",
    "        x = self.conv_layer_3(x)\n",
    "        x = self.conv_layer_4(x)\n",
    "        x = self.conv_layer_5(x)\n",
    "        x = self.conv_layer_6(x)\n",
    "        x = self.conv_layer_7(x)\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc_layer(x)\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "royal-plate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0021,  0.0357,  0.0950, -0.0139, -0.0605,  0.0507,  0.0057,  0.1063,\n",
       "          0.1422, -0.0256],\n",
       "        [-0.0455,  0.0758,  0.1003, -0.0226,  0.0140,  0.0129, -0.0250,  0.1055,\n",
       "          0.1140,  0.0038],\n",
       "        [ 0.0050,  0.0702,  0.1219, -0.0434, -0.0218,  0.0253, -0.0117,  0.0845,\n",
       "          0.1222,  0.0144],\n",
       "        [ 0.0265,  0.0235,  0.1170, -0.0175, -0.0115, -0.0412, -0.0321,  0.0846,\n",
       "          0.1110, -0.0755],\n",
       "        [-0.0023,  0.0348,  0.1024, -0.0860,  0.0108, -0.0112,  0.0132,  0.0941,\n",
       "          0.1382, -0.0342],\n",
       "        [ 0.0087,  0.0703,  0.1140, -0.0419,  0.0204,  0.0085, -0.0274,  0.0853,\n",
       "          0.1541, -0.0207],\n",
       "        [ 0.0239,  0.0326,  0.0654, -0.0582,  0.0095, -0.0230, -0.0152,  0.0665,\n",
       "          0.1489, -0.0499],\n",
       "        [ 0.0115,  0.0379,  0.1636, -0.0363, -0.0177, -0.0018, -0.0176,  0.1083,\n",
       "          0.1524, -0.0904],\n",
       "        [-0.0252,  0.0895,  0.1325, -0.0723,  0.0135,  0.0224,  0.0129,  0.0903,\n",
       "          0.1094, -0.0263],\n",
       "        [-0.0087,  0.0764,  0.1340, -0.0196, -0.0500,  0.0258, -0.0187,  0.0637,\n",
       "          0.1718, -0.0256]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MobileNet(width_multiplier=1, num_classes=10).to(device)\n",
    "x = torch.randn(10, 3, IMG_SIZE, IMG_SIZE).to(device)\n",
    "model(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
