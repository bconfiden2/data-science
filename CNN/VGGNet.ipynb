{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "informational-greeting",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "printable-parallel",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available else 'cpu'\n",
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "banned-dependence",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG_net(nn.Module):\n",
    "    def __init__(self, architecture, in_channels=3, num_class=10):\n",
    "        super(VGG_net, self).__init__()\n",
    "        self.num_pooling = 0\n",
    "        self.in_channels = in_channels\n",
    "        self.conv_layers = self.create_conv_layers(architecture)\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(512 * IMG_SIZE//(2**self.num_pooling) * IMG_SIZE//(2**self.num_pooling), 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            \n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.5),\n",
    "            \n",
    "            nn.Linear(4096, num_class)\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc_layers(x)\n",
    "        return x\n",
    "    \n",
    "    \n",
    "    def create_conv_layers(self, architecture):\n",
    "        layers = []\n",
    "        in_channels = self.in_channels\n",
    "        \n",
    "        for x in architecture:\n",
    "            if type(x) == int:\n",
    "                out_channels = x\n",
    "                layers += [nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=3, stride=1, padding=1),\\\n",
    "                           nn.BatchNorm2d(x),\\\n",
    "                           nn.ReLU()]\n",
    "                in_channels = x\n",
    "            elif x == 'M':\n",
    "                self.num_pooling += 1\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "                \n",
    "        return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cubic-maker",
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG16 = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "featured-silver",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3763, -0.0303,  0.0065, -0.1575,  0.3476,  0.0674,  0.2578, -0.0704,\n",
       "         -0.3504, -0.2901],\n",
       "        [ 0.0431, -0.1185, -0.0736, -0.2434,  0.4924, -0.4610,  0.0632, -0.0484,\n",
       "         -0.1141,  0.1746],\n",
       "        [ 0.0951,  0.4222, -0.1675,  0.0180,  0.0664, -0.1375, -0.1733, -0.2234,\n",
       "         -0.4054, -0.0530],\n",
       "        [-0.0689,  0.0801,  0.1954, -0.1408,  0.2169,  0.3348, -0.1144, -0.1439,\n",
       "         -0.2228, -0.3067],\n",
       "        [ 0.1803, -0.1716, -0.1095,  0.1325,  0.2146, -0.2766,  0.0600, -0.1177,\n",
       "         -0.4977, -0.3634],\n",
       "        [ 0.4258,  0.0939, -0.1024, -0.1377,  0.2563,  0.4514,  0.0478, -0.0517,\n",
       "         -0.0296,  0.0195],\n",
       "        [ 0.0665,  0.3284, -0.3230,  0.0137,  0.1747, -0.0195, -0.0428, -0.4560,\n",
       "          0.1536,  0.0232],\n",
       "        [-0.0749, -0.2347, -0.1689,  0.0582,  0.3567,  0.1214, -0.2004, -0.5142,\n",
       "          0.2490, -0.4662],\n",
       "        [-0.1895, -0.2625, -0.0105,  0.1862,  0.0600,  0.1485, -0.5182, -0.3595,\n",
       "         -0.3979,  0.5013],\n",
       "        [ 0.2364, -0.1169, -0.0995, -0.0463,  0.1193,  0.0318, -0.2153,  0.0897,\n",
       "         -0.3583, -0.2859]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = VGG_net(VGG16, in_channels=3, num_class=10).to(device)\n",
    "x = torch.randn(10, 3, IMG_SIZE, IMG_SIZE).to(device)\n",
    "model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "previous-niagara",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
